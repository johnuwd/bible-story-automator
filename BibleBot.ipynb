{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d3c1b2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# @title 1. Install Libraries (Fixed for MoviePy 1.0.3)\n",
    "# 1. Install the main AI libraries\n",
    "!pip install -q --upgrade google-generativeai edge-tts torch torchaudio torchvision diffusers transformers accelerate\n",
    "\n",
    "# 2. Force install the specific version of MoviePy that supports .editor\n",
    "!pip install moviepy==1.0.3\n",
    "\n",
    "!pip install -q groq\n",
    "\n",
    "# 3. Install ImageMagick (Required for text/video processing)\n",
    "!apt install imagemagick\n",
    "!cat /etc/ImageMagick-6/policy.xml | sed 's/none/read,write/g'> /etc/ImageMagick-6/policy.xml\n",
    "\n",
    "print(\"✅ Installation Complete - MoviePy 1.0.3 Restored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa88f59",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# @title Bible Story Bot (Full Pipeline)\n",
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "import torch\n",
    "import edge_tts\n",
    "from groq import Groq\n",
    "from diffusers import StableDiffusionXLPipeline, EulerDiscreteScheduler\n",
    "from moviepy.editor import *\n",
    "from google.colab import drive\n",
    "from deep_translator import GoogleTranslator\n",
    "from google.oauth2.credentials import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "\n",
    "# --- CONFIG ---\n",
    "GROQ_API_KEY = \"YOUR_GROQ_KEY_HERE\"\n",
    "DRIVE_FOLDER = \"/content/drive/MyDrive/BibleStories\"\n",
    "TOPIC = \"The Story of Joseph\"\n",
    "\n",
    "# --- SETUP ---\n",
    "drive.mount('/content/drive')\n",
    "os.makedirs(DRIVE_FOLDER, exist_ok=True)\n",
    "\n",
    "# Load Models\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"Lykon/dreamshaper-xl-1-0\", \n",
    "    torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\"\n",
    ")\n",
    "pipe.enable_model_cpu_offload()\n",
    "\n",
    "# --- 1. GENERATE SCRIPT ---\n",
    "def generate_script(topic):\n",
    "    client = Groq(api_key=GROQ_API_KEY)\n",
    "    glossary = \"God -> దేవుడు (Devudu)\\nJoseph -> యోసేపు (Yosepu)\" # Add full list here\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are a Telugu Grandmother. Tell the story of {topic}.\n",
    "    {glossary}\n",
    "    Output JSON with 'scenes' (10), 'lesson' (1), 'blessing' (1).\n",
    "    - narration: Telugu\n",
    "    - visual: English\n",
    "    \"\"\"\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama-3.1-70b-versatile\",\n",
    "        messages=[{\"role\":\"system\", \"content\":prompt}],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    return json.loads(completion.choices[0].message.content)\n",
    "\n",
    "# --- 2. ASSETS & VIDEO ---\n",
    "async def process_video(script):\n",
    "    clips = []\n",
    "    translator = GoogleTranslator(source='auto', target='en')\n",
    "    \n",
    "    segments = script['scenes'] + [script['lesson']] + [script['blessing']]\n",
    "    \n",
    "    for i, seg in enumerate(segments):\n",
    "        # Audio\n",
    "        audio_path = f\"audio_{i}.mp3\"\n",
    "        await edge_tts.Communicate(seg['narration'], \"te-IN-ShrutiNeural\").save(audio_path)\n",
    "        \n",
    "        # Image (Safety Net)\n",
    "        try: visual = translator.translate(seg['visual'])\n",
    "        except: visual = seg['visual']\n",
    "        \n",
    "        img_path = f\"image_{i}.png\"\n",
    "        pipe(prompt=f\"3D disney style, {visual}\", height=1024, width=1024).images[0].save(img_path)\n",
    "        \n",
    "        # Clip\n",
    "        audio = AudioFileClip(audio_path)\n",
    "        clip = ImageClip(img_path).set_duration(audio.duration+0.5).set_audio(audio)\n",
    "        clips.append(clip)\n",
    "        \n",
    "    final = concatenate_videoclips(clips, method=\"compose\")\n",
    "    out_path = f\"{DRIVE_FOLDER}/{TOPIC}.mp4\"\n",
    "    final.write_videofile(out_path, fps=24)\n",
    "    return out_path\n",
    "\n",
    "# --- 3. UPLOAD ---\n",
    "def upload(file_path):\n",
    "    token_path = f\"{DRIVE_FOLDER}/token.json\"\n",
    "    creds = Credentials.from_authorized_user_file(token_path)\n",
    "    youtube = build('youtube', 'v3', credentials=creds)\n",
    "    \n",
    "    body = {\n",
    "        'snippet': {'title': f\"{TOPIC} (Telugu)\", 'categoryId': '22'},\n",
    "        'status': {'privacyStatus': 'public', 'selfDeclaredMadeForKids': False}\n",
    "    }\n",
    "    youtube.videos().insert(part=\"snippet,status\", body=body, media_body=MediaFileUpload(file_path)).execute()\n",
    "\n",
    "# Run\n",
    "script = generate_script(TOPIC)\n",
    "video_path = await process_video(script)\n",
    "upload(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4cb01d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
